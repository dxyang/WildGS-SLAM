inherit_from: ./configs/wildgs_slam.yaml
scene: yawzi_2x_cc_ss1_reference_images # Replace with your scene name

stride: 2            # use every X image from the dataset

dataset: 'auv_rosbag'
data:
  input_folder: /srv/warplab/home/dxy/mast3r_experiments/reference_images
  output: ./output/yawzi_2x_cc_ss2_reference_images
cam:
  H: 540
  W: 960
  H_out: 360
  W_out: 480
  fx: 1020.90
  fy: 1020.90
  cx: 478.89
  cy: 236.69
  # H_edge: 0 # Uncomment this and the following line if you have edge cropping like in TUM datasets
  # W_edge: 0
  # distortion: [0.0, 0.0, 0.0, 0.0, 0.0] # Uncomment if you have distortion coefficients

tracking:
  buffer: 5000     # maximum number of keyframes that can be stored

mapping:
  Training:
    alpha: 0.8 # Increase this value to make rendering loss weighs more on rgb rather than depth
  uncertainty_params:
    # For outdoor dataset where the metric depth estimation is unstable,
    # I recommend to set this value to be 0.1 or even 0.
    uncer_depth_mult: 0.2

# # Uncomment the following lines to enable fast mode and GUI
fast_mode: False
gui: False

# # Uncomment the following lines to save online plotting data
mapping:
  online_plotting: True